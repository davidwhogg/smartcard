% this file is part of the Smart Card project.

\documentclass[letterpaper,12pt,preprint]{hack_aastex}

\usepackage{amsmath}
\usepackage{color}
\usepackage[pagebackref=false]{hyperref}
\definecolor{linkcolor}{rgb}{0,0,0.25}
\hypersetup{colorlinks=true,linkcolor=linkcolor,citecolor=linkcolor,
            filecolor=linkcolor,urlcolor=linkcolor}
\newcommand{\hurl}[1]{{\scriptsize\url{#1}}}

\usepackage{epsfig}
\usepackage{graphicx}
\newcommand{\sectionname}{Section}
\setlength{\headheight}{2ex}
\setlength{\headsep}{2ex}
\input{hogg_nasa}
\newcommand{\dd}{\,\mathrm{d}}
\newcommand{\bvec}[1]{{\ensuremath{{\boldsymbol{#1}}}}}
\pagestyle{myheadings}
\markright{\textsf{\footnotesize Hogg \& Foreman-Mackey / %
                   End-to-end probabilistic modeling of Kepler data}}

\usepackage{listings}
\lstset{%
    language=Python,
    basicstyle=\scriptsize\ttfamily,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    breaklines=false,
    breakatwhitespace=true,
    identifierstyle=\ttfamily,
    keywordstyle=\bfseries\color[rgb]{0.133,0.545,0.133},
    commentstyle=\color[rgb]{0.4,0.4,0.4},
    stringstyle=\color[rgb]{0.627,0.126,0.941},
}

\begin{document}

\section{Introduction?}

[todo] \Kepler\ rocks.

[todo] Small planets seem to be rocky.  Several habitable planets known.  None around a Sun-like star.  Why not?  Cite \figurename~\ref{fig:planet-properties}.

\ssfigure{figures/planet_properties.pdf}{0.60}{%
The properties of confirmed and candidate exoplanets from \Kepler.
Data from NASA Exoplanet Archive.
The candidates near the location of Earth (labeled by grey lines) are orbiting
lower-mass (cooler, fainter) stars and are therefore not true Earth analogs,
in terms of size, period, and temperature (or insolation).
\label{fig:planet-properties}}

[todo] We think these things will be rare, but there is a good chance the \Kepler\ data contains one, transiting.

[todo] There are photons to do it, but various issues:  Calibration, telescope variations, stellar stochastic variability, lack of understanding of the full system.

\section{A data-driven model of the \Kepler\ pixels}

Despite the impressive precision, \Kepler's photometry is plagued by
substantial ``systematics'' due to instrumental effects (pointing shifts,
temperature variations, \etc) and real astrophysical signals (stellar
variability, transiting exoplanets, \etc).
It is of significant scientific interest to separate these two types of
signals and much progress has been made towards removing instrumental
systematics while robustly retaining the astrophysical effects (CITE PDC, ARC,
\etc).
These algorithms are all based on a fundamental \emph{causal} argument: the
signals that are common across nearby targets must be due to instrumental
variations because there can be no causal connection between the astrophysical
objects.
The idea is simple but a lot of the work that goes into implementing these
models involves combating over-fitting.

We propose to implement a method based on the same argument that models the
instrumental effects \emph{at the pixel level} instead of in the photometry.
This method makes a prediction for the variability caused by the instrument in
a specific pixel at a specific time by using the pixel time series of similar
nearby (but causally disconnected) targets at different times.
This prediction can then be used to remove or model the systematics in various
ways but our current thinking is that this model is best used TODO photometry
of prediction.

We'll model the flux due to systematic variations in pixel $k$ of target
$n$ at time $t$ as
\begin{eqnarray}
f_{nk}(t) &=& \bvec{c}_{nk}^\mathrm{T}\cdot\bvec{f}_{\sim n}(t)
              + \epsilon_{nk}(t)
\end{eqnarray}
where $\bvec{f}_{\sim n}$ is the vector of some $K$ pixels around nearby
targets (not including $n$), $\bvec{c}_{nk}$ is a vector of linear weights,
and $\epsilon_{nk}$ represents the stochastic pixel noise.
There are many choices that must be made to evaluate this model but the main
ones are: (a) the number of pixels $K$ should be used in $\bvec{f}_{\sim n}$,
and (b) how the weights $\bvec{c}_{nk}$ are chosen.
Motivated by the standard techniques in the machine learning literature, we
advocate for a very large value of $K$ and use other techniques to regularize
and avoid over-fitting.
In particular, we choose to fit the coefficients $\bvec{c}$ using the light
curve in this pixel but at \emph{different times} $t^\prime$ where
$|t-t^\prime| > \Delta$.

\ssfigure{figures/kepler-20-plm.pdf}{0.60}{%
A comparison of photometric methods applied to quarter 9 of target Kepler-20,
a variable exoplanet host with 5 known transiting exoplanets.
This star is known to exhibit significant stellar variability and we chose it
as an example because the presearch data conditioning algorithm clearly
over-fits the signals.
With sensible choices for the hyperparameters of our data-driven model, the
resulting light curve retains more of the interesting astrophysical signals
and does not affect the transit depths.
\emph{Top:} the simple aperture photometry (black points) with the data-driven
prediction for the instrumental effects.
\emph{Middle:} the data-driven photometric light curve.
\emph{Bottom:} the presearch data conditioned light curve.
\label{fig:plm}}

[todo] What, precisely, do we propose?

\section{Optimized aperture photometry}

The astronomical community tends to think in terms of stellar flux estimators
(or photometric estimators) that are weighted linear sums of pixels.
If you have an image of an isolated star and you know it's position in the
image, the point-spread function, the approximate brightness of the star, and
all the parameters of the pixel-level noise model, it is possible to obtain a
photometric estimate of the star of this form (weighted linear sum of pixels)
that is optimized for signal-to-noise.
The estimator is a kind of ``matched filter''.
This result has been known for a long time (CITE THINGS).

Below (when we talk about \kpsf) we are going to consider more radical
photometric estimators.
But even within the restriction to estimators based on weighted linear sums,
there are advances to be made.
In the case of \Kepler\ the opportunities come from the fact that the data
are taken in an extremely uniform, homogeneous mode, but at the same time not
\emph{perfectly} homogeneous.
That is, the pointing of \Kepler\ is stable only at the hundredth-of-a-pixel
level (or maybe thousandth; we don't precisely know), and it undergoes
temperature and focus variations as it adjusts for attitude changes required
for data downlink operations.

If we think of the ``jitter'' or small unknown displacements of the angular
position of the satellite and the optics in focus or temperature changes as a
kind of ``noise'', then even though the individual pixel read-outs are
independent, the variance in the pixel space obtains non-trivial covariances:
The pointing and PSF variance maps onto a correlated pixel variance.

[todo] imagine we can estimate mean and covariance in a pixel patch

[todo] then we can make a signal-to-noise optimal photometric estimator

[todo] decisions about how to estimate mean and covariance.  Some ideas.

[todo] decisions about how to constrain or regularize the weights.  Some ideas.

[todo] include a figure that shows success.

[todo] what, precisely, do we propose?

\section{Flexible, non-parametric modeling of light curve variations}

[todo] Why are stochastic stellar variations a killer?  In what sense do they make naive $\chi^2$ fitting bad?

[todo] What is a non-parametric model?  What is a Gaussian Process?

[todo] What does the GP likelihood look like?

[todo] What are the hyperparameters and how can we set them; what do they do?

[todo] How does this relate to search and what searches are we going to do?

[todo] what, precisely, do we propose?

\section{The \Kepler\ focal plane}

[todo] Reminder of the importance of a LF, both for frequentists and Bayesians.

[todo] A full probability for the data given parameters would look like a causal model, with PSF, flat-field and so on.  Refer out to demos in the white paper.

[todo] What baby steps have we taken so far and what kinds of decisions will there be?

[todo] How does this interact with the \PLM\ and the \OWL?  Is it in concert or conflict?  Modify summary to be consistent.

[todo] what, precisely, do we propose?

\section{Management plan and schedule}

[todo] In the first year, we do OWL and George.  Start search.

[todo] In the second year, we do PLM.  Finish search.

[todo] In the third year we do kpsf and re-run search.

\clearpage
\begin{thebibliography}{}\raggedright%

\bibitem[Petigura \etal(2013)]{petigura}
Petigura, E.~A., Howard, A.~W., \& Marcy, G.~W.\ 2013,
Proceedings of the National Academy of Science, 110, 19273

\end{thebibliography}

\end{document}
