% this file is part of the Smart Card project.

% to-do
% -----
% - outline
% - write
% - submit
% - spend

\documentclass[letterpaper,12pt]{article}
\usepackage{epsfig}
\usepackage{graphicx}
\newcommand{\sectionname}{Section}
\setlength{\headheight}{2ex}
\setlength{\headsep}{3ex}
\input{hogg_nasa}
\newcommand{\Untrendy}{\package{Untrendy}}
\newcommand{\Turnstile}{\package{IronHorse}}
\newcommand{\Bart}{\package{Bart}}
\newcommand{\emcee}{\package{emcee}}
\newcommand{\TheCreator}{\package{TheCreator}}
\pagestyle{myheadings}
\markright{\textsf{\small Hogg \& Foreman-Mackey / probabilistic modeling of Kepler data}}
\begin{document}

\paragraph{project summary:}

The \Kepler\ observatory has provided the most important and
scientifically productive data set ever for the study of exoplanets;
it has yielded enormous numbers of new exoplanets and exoplanetary
systems; it has generated unprecedented discoveries, measurements, and
insights in the domain of exoplanet science.  This proposal is to
systematically re-analyze all of the \Kepler\ data from the ground up,
to verify and improve upon the tremendously successful
\Kepler-team-led analyses of the data, and to provide new inference
capabilities to the entire astrophysics community.  In particular,
\textbf{the proposal is to design, build, and release to the public
  four modular, novel, easy-to-use tools for probabilistic inference
  of exoplanet populations in the \Kepler\ data.}

The project team will design, build, and release four non-trivial
algorithmic methods (and corresponding software tools): The first is
\Untrendy, a system for flexibly but responsibly modeling the
combination of tiny spacecraft photometric issues and stellar
variability that makes every \Kepler\ target variable even in the
calibrated data stream.  These effects, if unmodeled, are far larger
than the exoplanet transits of greatest importance.  The second is
\Turnstile, a brute-force generative-modeling machinery that creates
and tests against enormous numbers of \Kepler\ targets---each of which
has enormous numbers of observations---enormous numbers of
exoplanetary hypotheses.  This is how exoplanet candidates are found
(or should be found).  The third is \Bart, an inference package that
returns responsible, properly marginalized parameter estimates under
parameterized (or non-parametric) prior probability density functions
for exoplanet system properties.  The fourth is \TheCreator, a
hierarchical modeling framework and software system that permits
probabilistic inference of the true distribution of exoplanetary
system parameters (``architecture'' in the lingo), starting at
parameter estimation and including all the information coming not just
from well measured systems but also from all the (numerous) marginal
and null detections among the \Kepler\ targets.

The common thread joining all of these projects is probabilistic
inference.  The project team members are known for creating useful
tools and methods for principled inference, most notably with
generative, justified, causal models and Markov Chain Monte Carlo
(MCMC).  The \Untrendy\ system is novel because it is based on a model
that is very flexible where it needs to be, but inflexible (relative
to its competitors) where it doesn't.  The \Turnstile\ machinery can
make discoveries that predecessors have missed because it makes
principled approximations to full generative modeling of the data
without the enormous computational cost.  It also capitalizes on
current computer architecture (GPU) where it can.  The \Bart\ package
capitalizes on the project team's expertise in fast, self-tuning MCMC
to perform parameter estimation efficiently.  Part of its core design
philosophy is flexibility in parameterization of systems; this makes
it easy to propagate results---even from different systems with very
different multiplicities---into population inference.
\TheCreator\ makes use of concepts from probabilistic graphical models
(Bayesian networks) to incorporate ideas about causal mechanisms and
quantitatively precise noise models into global population inferences.

Each of the four packages embodies a set of important ideas in data
analysis and will be expressed in the form of easy-to-use,
easy-to-modify, public, open-source software, released under an
open-source license.  The idea is to make all results of the project
easily reproducible and extendable by anyone.

\section{why re-analyze \Kepler\ data?}

The \Kepler\ team is one of the most successful collaborations in the
history of astronomy, and the \Kepler\ data are by no means trivial to
understand and use.  Why would even a plucky twosome consider
competing with this extremely capable group?  The answer is that this
is \emph{not} a proposal to \emph{compete} with the \Kepler\ team.
This is a proposal to enhance the capabilities of the \Kepler\ mission
and give new tools to the entire community to increase the scientific
return from the \Kepler\ data (and many related and future data sets).

The first reason that it makes sense to re-consider the \Kepler\ data
from the ground up is the simple point that it is valuable to have
multiple eyes on the problem.  We bring different prejudices,
different intuitions, and different expertise than exists on the
\Kepler\ team.  In addition, we can analyze the \Kepler\ data in a
more open-ended way since we do not bear the responsibility of
delivering results according to existing schedules and requirements.
That said, we very much hope to create methods and code that make the
\Kepler\ team products more valuable and easier to deliver.

The second reason it makes sense for us to take an independent look at
the \Kepler\ data is that we will bring a strong probabilistic,
causal, generative model approach to everything we do.  In each
component of this project, we are trying to write down a probability
for the data given the parameters, and in each component we are trying
to have the relationship of the parameters to the predictions obey
deep ideas we have about the physical or causal processes that
generate the data.  For certain kinds of (endearing) fanatics---or
perhaps more correctly, under certain kinds of restrictive
assumptions---these probabilistic approaches to data analysis are
guaranteed to succeed over more heuristic methods.  We have god on our
side, in this sense.  But because we are free from project
requirements, we can take a more principled approach to the data
analysis and see if that delivers better results.  If it does (because
we are proposing to generate public, open-source, easy-to-use code)
\emph{everybody wins.}

Finally, the most important reason to bring new people and new ideas
to the \Kepler\ data is that the \Kepler\ data are so damned
important.  The vast majority of known exoplanets are
\Kepler\ discoveries (CITE), and each \Kepler\ discovery brings with
it so much important information about each planetary system (CITE).
The data set has included many multiple-planet systems, and supported
preliminary studies of population statistics, such as multiplicity and
inclination distributions (CITE).  These studies have been made
possible in part by the scale and in part by the simplicity of the
\Kepler\ experiment; it has created a statistically useable sample.
Although \Kepler\ is just the first step of \NASA's exoplanet journey,
it is the best data set in it's class right now, and will retain
unique capabilities for many years to come.  Furthermore, many future
data sets (for example that from \TESS; CITE), produce data that are
\Kepler-like in many ways.  \textbf{If we can take the most valuable
  data set in exoplanetary astrophysics and make it substantially more
  valuable with an ADAP-scale project, we can deliver to
  \NASA\ outstanding science per dollar.}

Even if you are convinced that the data need to be re-analyzed, why
should they be reanalyzed by this team?  Although the proposers do not
have a long history in exoplanet science, we do have some experience,
breaking ground in the area of hierarchical modeling of exoplanet
populations (CITE Hogg), and telescope light-field modeling for
exoplanet direct detection and spectroscopy (CITE Oppenheimer).  Much
more importantly, the proposal team has enormous experience in two
areas that are crucial if we are going to squeeze more information out
of the \Kepler\ data stream: We have great experience with calibration
and sensitive statistical analysis of enormous astrophysical data
sests (CITE some eg papers), and we are among the world leaders in
probabilistic modeling of astrophysical data sets (CITE some eg
papers).  In particular, Co-I Hogg was partially responsible for the
precise self-calibration of the \observatory{Sloan Digital Sky Survey}
imaging data (CITE Padmanabhan), which in turn led (almost directly)
to discoveries such as ultra-faint Milky Way companions Willman I
(CITE) and XXX (CITE) and the detection of the baryon acoustic feature
in the large-scale structure (CITE).  These two
strengths---calibration and probabilistic modeling---are not unique to
the proposing team, but their combination is unusual and puts us in a
very strong position to deliver extremely valuable new methods to the
\Kepler\ team and larger community.

\section{de-trending}

...running median is too flexible most of the time, and not flexible enough when there are discontinuities

...DFM: Explain what is currently done---or at least \emph{said to be done}.  With citations.

...DFM: Explain what \Untrendy\ will do in its first release.  And demo figure.

...Hogg:  Explain what \Untrendy\ might do in future releases.

\section{fast, approximate hypothesis testing}

...fastness

...DFM:  Explain what is currently done and how.  With citations.

...Hogg:  Explain what \Turnstile\ will do in its first release.  DFM:  And demo figure.

...Hogg:  Explain what future releases of \Turnstile\ might do.

\section{probabilistic parameter estimation}

...DFM:  Explain the range of things that are currently done.  With citations and possibly also criticisms where appropriate.

...DFM:  Explain what \Bart\ will do in its first release.  And demo figures.

...Hogg:  What might \Bart\ do in future releases?

\section{hierarchical population inference}

...pgm intro

...DFM:  Explain what is currently done, perhaps concentrating on Tremaine paper and competitors.  Also we should touch on theory here.

...Hogg:  What will \TheCreator\ do?

\section{side projects}

...GALEX project

...false-positive detection and characterization

...variable-star science

\section{management plan}

...roles of co-Is

...roles of postdoc and undergraduate researchers

...schedule and deliverables

\end{document}
