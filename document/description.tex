% this file is part of the Smart Card project.

% to-do
% -----
% - outline
% - write
% - submit
% - spend

\documentclass[letterpaper,12pt]{article}
\usepackage{epsfig}
\usepackage{graphicx}
\newcommand{\sectionname}{Section}
\setlength{\headheight}{2ex}
\setlength{\headsep}{3ex}
\input{hogg_nasa}
\newcommand{\kplr}{\package{kplr.co}}
\newcommand{\Untrendy}{\package{Untrendy}}
\newcommand{\Turnstile}{\package{IronHorse}}
\newcommand{\Bart}{\package{Bart}}
\newcommand{\emcee}{\package{emcee}}
\newcommand{\TheCreator}{\package{TheCreator}}
\newcommand{\KIC}{\textsl{KIC}}
\newcommand{\KOI}{\textsl{KOI}}
\pagestyle{myheadings}
\markright{\textsf{\small Hogg \& Foreman-Mackey / probabilistic modeling of Kepler data}}
\begin{document}

\section{why re-analyze \Kepler\ data?}

The \Kepler\ team is one of the most successful collaborations in the
history of astronomy, and the \Kepler\ data are by no means trivial to
understand and use.  Why would even a plucky twosome consider
competing with this extremely capable group?  The answer is that this
is \emph{not} a proposal to \emph{compete} with the \Kepler\ team.
This is a proposal to enhance the capabilities of the \Kepler\ mission
and give new tools to the entire community to increase the scientific
return from the \Kepler\ data (and many related and future data sets).

The first reason that it makes sense to re-consider the \Kepler\ data
from the ground up is the simple point that it is valuable to have
multiple eyes on the problem.  We bring different prejudices,
different intuitions, and different expertise than exists on the
\Kepler\ team.  In addition, we can analyze the \Kepler\ data in a
more open-ended way since we do not bear the responsibility of
delivering results according to existing schedules and requirements.
That said, we very much hope to create methods and code that make the
\Kepler\ team products more valuable and easier to deliver.

The second reason it makes sense for us to take an independent look at
the \Kepler\ data is that we will bring a strong probabilistic,
causal, generative model approach to everything we do.  In each
component of this project, we are trying to write down a probability
for the data given the parameters, and in each component we are trying
to have the relationship of the parameters to the predictions obey
deep ideas we have about the physical or causal processes that
generate the data.  For certain kinds of (endearing) fanatics---or
perhaps more correctly, under certain kinds of restrictive
assumptions---these probabilistic approaches to data analysis are
guaranteed to succeed over more heuristic methods.  We have god on our
side, in this sense.  But because we are free from project
requirements, we can take a more principled approach to the data
analysis and see if that delivers better results.  If it does (because
we are proposing to generate public, open-source, easy-to-use code)
\emph{everybody wins.}

Finally, the most important reason to bring new people and new ideas
to the \Kepler\ data is that the \Kepler\ data are so damned
important.  The vast majority of known exoplanets are
\Kepler\ discoveries (CITE), and each \Kepler\ discovery brings with
it so much important information about each planetary system (CITE).
The data set has included many multiple-planet systems, and supported
preliminary studies of population statistics, such as multiplicity and
inclination distributions (CITE).  These studies have been made
possible in part by the scale and in part by the simplicity of the
\Kepler\ experiment; it has created a statistically useable sample.
Although \Kepler\ is just the first step of \NASA's exoplanet journey,
it is the best data set in it's class right now, and will retain
unique capabilities for many years to come.  Furthermore, many future
data sets (for example that from \TESS; CITE), produce data that are
\Kepler-like in many ways.  \textbf{If we can take the most valuable
  data set in exoplanetary astrophysics and make it substantially more
  valuable with an ADAP-scale project, we can deliver to
  \NASA\ outstanding science per dollar.}

Even if you are convinced that the data need to be re-analyzed, why
should they be reanalyzed by this team?  Although the proposers do not
have a long history in exoplanet science, we do have some experience,
breaking ground in the area of hierarchical modeling of exoplanet
populations (CITE Hogg), and telescope light-field modeling for
exoplanet direct detection and spectroscopy (CITE Oppenheimer).  Much
more importantly, the proposal team has enormous experience in two
areas that are crucial if we are going to squeeze more information out
of the \Kepler\ data stream: We have great experience with calibration
and sensitive statistical analysis of enormous astrophysical data
sests (CITE some eg papers), and we are among the world leaders in
probabilistic modeling of astrophysical data sets (CITE some eg
papers).  In particular, Co-I Hogg was partially responsible for the
precise self-calibration of the \observatory{Sloan Digital Sky Survey}
imaging data (CITE Padmanabhan), which in turn led (almost directly)
to discoveries such as ultra-faint Milky Way companions Willman I
(CITE) and XXX (CITE) and the detection of the baryon acoustic feature
in the large-scale structure (CITE).  These two
strengths---calibration and probabilistic modeling---are not unique to
the proposing team, but their combination is unusual and puts us in a
very strong position to deliver extremely valuable new methods to the
\Kepler\ team and larger community.

\section{an API for \Kepler\ data}

foo

\section{de-trending}

Key features of \project{untrendy}:
\begin{itemize}
\item Very scalable/local compared to ``Bayesian'' algorithm. Similar to
      a more robust windowed median.
\item Finds discontinuities---called Sudden Pixel Sensitivity Dropouts (SPSD)
      by the Kepler team---automatically and corrects the trends. There is a
      claim in the literature (with reference to a non-existent
      Kolodziejczak 2012 paper) that PDC in the Kepler pipeline 8.0 will deal
      with this but it's not included as part of the standard de-trending.
\item Untrendy is probably less robust to maintaining intrinsic stellar
      variability but if the goal is a \emph{planet search} then something
      scalable that removes any non-planetary signal is interesting.
\end{itemize}

\paragraph{Standard Pre-search Data Conditioning (PDC)}
The first step in the Kepler plant search is to remove systematic trends in
the data.
Transit signals can be significantly diluted by both intrinsic stellar
variability and instrumental effects. In general, these features can be much
larger than the transit signals so care must be taken to separate
blah blah Sudden Pixel Sensitivity Dropouts (SPSDs)

\paragraph{Standard Practice}
For most precision experiments, the light curves corrected using PDC are not
sufficiently de-trended.
It is standard practice (Dressing, for example) to normalize fluxes by a
running windowed median with a width of a few days (this is a free parameter).
This method actually works very well.
It corrects for most of the smooth systematic signals and can remove any
stellar variability on time scales longer than the window width.
Using the median is extremely robust to outliers so if you use a wide enough
window, this procedure doesn't significantly affect the transit signal.
It is important to note that if you're looking to study the parameters of the
\emph{planets} it is often preferable to remove the effects of stellar
variability.
It would probably not be a good idea to do something as simplistic as a
windowed median if you're interested in studying the properties of variable
stars.
This procedure runs into serious trouble when it encounters a SPSD or any
other sharp discontinuity.
The implicit background model must be smooth even across discontinuities so it
will introduce significant structured residuals at SPSDs.
The most responsible procedure would probably be to simply discard the data
near these points (as with PDC) but the literature is not very clear on how
this is done in practice.


\paragraph{``Bayesian'' MAP-PDC}
\begin{itemize}
\item uses co-trending with surrounding stars to remove systematic trends that
\emph{are correlated} between nearby sources.
\item should also deal with SPSDs (word on the street) but the paper doesn't
exist.
\item this will be included in the ``next'' official release of the Kepler
pipeline but it hasn't been yet so we can't compare.
\item this is probably FAR better for studies of variable stars.
\item the other side of the same coin is that it probably isn't as good for
studying planets unless your model of the star includes a model of stellar
variability\ldots and if you're going to that trouble, why aren't you forward
modelling the systematics too.
\item also, if you're trying to \emph{find} exoplanets, a more destructive
algorithm is probably better suited.
\end{itemize}


\paragraph{Untrendy}
Our algorithm and implementation---currently titled \Untrendy---takes a
somewhat different approach.

...Hogg:  Explain what \Untrendy\ might do in future releases.

\begin{figure}[p]
\includegraphics[width=\textwidth]{figures/untrend_data.pdf}
\caption{Demo of untrendy.\label{fig:untrendy}}
\end{figure}

\section{fast, approximate hypothesis testing}

...fastness

...DFM:  Explain what is currently done and how.  With citations.

...Hogg:  Explain what \Turnstile\ will do in its first release.  DFM:  And demo figure.

...Hogg:  Explain what future releases of \Turnstile\ might do.

\section{probabilistic parameter estimation}

...DFM:  Explain the range of things that are currently done.  With citations and possibly also criticisms where appropriate.

...DFM:  Explain what \Bart\ will do in its first release.  And demo figures.

...Hogg:  What might \Bart\ do in future releases?

\section{hierarchical population inference}

...pgm intro

...DFM:  Explain what is currently done, perhaps concentrating on Tremaine paper and competitors.  Also we should touch on theory here.

...Hogg:  What will \TheCreator\ do?

\section{side projects}

...GALEX project

...false-positive detection and characterization

...variable-star science

\section{management plan}

This project is the PhD dissertation project of Co-I Foreman-Mackey;
in this sense Foreman-Mackey is the scientific lead of the project,
making decisions about scientific priorities and the ordering of
experiments and code enhancements.  PI Hogg is the faculty advisor on
this dissertation; in this sense Hogg is the management lead of the
project, ensuring that deadlines get met, papers get written, and code
gets properly documented and released.  The budget also includes a
small amount of support for an additional part-time graduate student
and postdoc.  These are budgeted to support short-term scentific
collaborations that make use of the software or improve it.  That is,
some of the sub-parts of the project can be executed by new graduate
students or postdocs at NYU.

The project is budgeted for three years of project lifetime.  An
approximate schedule is the following

\paragraph{first year:}
Complete and release version~1.0 of \kplr\ API.  Release version~0.1
of \Untrendy, \Turnstile, and \Bart, executing the first stages of
approximation identified above.  Submit short papers describing these
codes, comparing them with standard community practice, and showing
first results.  Execute \Untrendy\ and \Turnstile\ on the entire \KIC;
publication of all candidate transiting exoplanets, especially those
previously unknown.  Execute \Bart\ on the best or most interesting of
those companions, with an eye to exoplanet characterization and
false-positive rejection.

\paragraph{second year:}
Submit papers describing the results of the \Untrendy, \Turnstile, and
\Bart\ from the first year.  Complete and release version~0.1 of
\TheCreator, executing the simplest meaningful graphical model, as
described above.  Execute \Bart\ and \TheCreator\ on the complete set
of exoplanet candidates geenerated in the first year.  Submit paper
describing those results.  With feedback from this full ``closed
loop'', re-prioritize enhancements to \Untrendy\ and \Turnstile; add
features to \Bart.  Complete and release Version~0.2 code for these
packages.  Start side projects on stellar variability, eclipsing
binaries, transit-timing variations, or limb-darkening as appropriate.

\paragraph{third year:}
Following up best hints in results from \TheCreator\ in the second
year, complexify or adjust the graphical model, or launch multiple
models for competition.  Re-run everything on the entire \KIC\ to
update the population analysis to incorporate all improvements.
Submit papers describing improved software and new results.  Complete
side projects and submit papers.  Make final decisions about final
code versions, final code adjustments, documentation, and hosting and
release Version~1.0 for all four of \Untrendy, \Turnstile, \Bart, and
\TheCreator, along with (possibly very short) papers on arXiv or ASCL.

\end{document}
