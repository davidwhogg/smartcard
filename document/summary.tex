% this file is part of the Smart Card project.

\documentclass[letterpaper,12pt]{article}
\usepackage{epsfig}
\usepackage{graphicx}
\newcommand{\sectionname}{Section}
\input{hogg_nasa}
\addtolength{\textheight}{\headheight}
\addtolength{\textheight}{\headsep}
\setlength{\headheight}{0ex}
\setlength{\headsep}{0ex}
\pagestyle{empty}
\begin{document}

The \Kepler\ Satellite data have been used to find thousands of exoplanets;
it has generated unprecedented discoveries, measurements, and insights.
In particular, it has found good evidence for rocky planets in or near the
habitable zones of low-mass stars.
It has yet, however, to find a true Earth Analog, or Earth-like planet on a
year-ish orbit around a Sun-like star.
This is not for lack of photons:
It is both the case that transiting Earth Analogs are expected to be rare, and
that these discoveries are the most challenging:
There is a small number of transits within the Mission lifetime,
uncalibrated variation in spacecraft (s/c) temperature and pointing,
and intrinsic stellar variability.
Here we \textbf{propose to create four software systems}, each of which will
address one or more of these challenges.
We also \textbf{propose to run these software systems on the \Kepler\ Data,
providing back to the entire community value-added data} that are more valuable
for almost any scientific question.

The first---the \PLM---is a data-driven, pixel-level, self-calibration of the
\Kepler\ Data pixel values.  
The idea is that (because the design of the \Kepler\ Satellite is so simple)
the s/c variability lives in a low-dimensionality space of pointing,
temperature, focus, and maybe some integrals or derivatives of those.
Inasmuch as these variations imprint on the pixels, they should be shared among
collections of pixels.
The \PLM\ builds a predictive model for every one of the $10^6$-ish pixels at
every one of the $10^5$-ish read-out epochs, using a combination of a
train-and-test framework and strong regularization to avoid over-fitting.
This model can potentially model out essentially all of the s/c-induced
variability in \Kepler\ Data lightcurves.

The second---the \OWL---is a method for generating rigid, frequentist
photometric estimators that are optimized for signal-to-noise in the presence
of correlated pixel noise.
The only reason that pixels...

The third---\George---is 

The fourth is \kpsf

Each of the four packages is not just code for \Kepler\ but also embodies
important ideas in data analysis.
Each will be released as easy-to-use, easy-to-modify, public, open-source
software, released under the MIT open-source license.
The idea is to make all results of the project easily useable, reproducible, and
extendable by anyone.

\end{document}

systematically re-analyze all of the \Kepler\ data from the ground up,
to verify and improve upon the tremendously successful
\Kepler-team-led analyses of the data, and to provide new inference
capabilities to the entire astrophysics community.  In particular,
\textbf{this proposal is to design, build, and release to the public
  four modular, novel, easy-to-use tools for probabilistic inference
  of exoplanet populations in the \Kepler\ data.}

The first is
\kplr, an application programming interface to the public
\Kepler\ data---and related and corresponding data from other
investigators, surveys, and missions---available at the Mikulski
Archive at Space Telescope and the Exoplanet Archive, making the data
and \Kepler\ pipeline outputs easier to fetch and manipulate with
automated software systems.  The second is \Untrendy, a system for
flexibly but responsibly modeling the combination of tiny spacecraft
photometric issues and stellar variability that makes every
\Kepler\ target variable even in the calibrated data stream.  These
effects, if unmodeled, are far larger than the exoplanet transits of
greatest importance.  The third is \Bart, an inference package that
returns responsible, properly marginalized parameter estimates under
parameterized (or non-parametric) prior probability density functions
for exoplanet system properties.  The fourth is \TheCreator, a
hierarchical modeling framework and software system that permits
probabilistic inference of the true distribution of exoplanetary
system parameters (``architecture'' in the lingo), starting at
parameter estimation and including all the information coming not just
from well measured systems but also from all the (numerous) marginal
and null detections among the \Kepler\ targets.

The common thread joining all of these projects is probabilistic
inference.  The project team members are known for creating useful
tools and methods for principled inference, most notably with
generative, justified, causal models and Markov Chain Monte Carlo
(MCMC).  The \Untrendy\ system is novel because it is based on a model
that is very flexible where it needs to be, but inflexible (relative
to its competitors) where it doesn't.  The \Bart\ package capitalizes
on the project team's expertise in fast, self-tuning MCMC to perform
parameter estimation efficiently.  Part of its core design philosophy
is flexibility in parameterization of systems; this makes it easy to
propagate results---even from different systems with very different
multiplicities---into population inference.  Also, the flexibility of
the model, particularly as regards limb-darkening profiles for the
host stars, makes it good for false-positive detection.
\TheCreator\ makes use of concepts from probabilistic graphical models
(Bayesian networks) to incorporate ideas about causal mechanisms and
parameterized or non-parametric selection functions and detection efficiencies into global population inferences.
Because it builds on the other components of the project, it has
flexibility to use the heterogeneous data obtainable through \kplr,
and work in different ``projections'' of the parameter space available
through \Bart.

\end{document}
